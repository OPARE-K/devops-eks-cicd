# ğŸš€ DevOps CI/CD on AWS EKS with Blue/Green Deployments

This project demonstrates a **production-grade CI/CD pipeline** deploying a containerized app on **Amazon EKS** using **Terraform, GitHub Actions, Docker, and Kubernetes**. It follows a **Blue/Green deployment strategy** to ensure zero-downtime rollouts.

---

## ğŸ“¦ Features
- Infrastructure as Code with **Terraform**
- **Amazon EKS** cluster with managed node groups
- **Amazon ECR** for container image storage
- **GitHub Actions** CI/CD pipeline with OIDC authentication
- **Dockerized application** deployed to Kubernetes
- **Blue/Green Deployment** strategy for safe rollouts
- Public **LoadBalancer Service** exposing the app

---

## ğŸ— Architecture

![architecture](./docs/architecture-diagram.png)

**Flow:**
1. Developer pushes code â†’ GitHub Actions triggers.
2. GitHub Actions builds Docker image, pushes to ECR.
3. Pipeline deploys new image as Green deployment.
4. Health check runs on Green.
5. Service flips from Blue â†’ Green if successful.
6. Blue is scaled down (optional).

---

## âš™ï¸ Tech Stack
- **AWS EKS**
- **Terraform**
- **Docker**
- **Kubernetes (kubectl)**
- **GitHub Actions**
- **Amazon ECR**

---

## ğŸ”‘ Secrets Configuration
Set the following in your GitHub Repo â†’ Settings â†’ Secrets and Variables â†’ Actions:

- `AWS_ROLE_TO_ASSUME` â†’ IAM role ARN (from Terraform output `oidc_role_arn`)  
- `AWS_REGION` â†’ e.g., `eu-west-2`  
- `ECR_REPO` â†’ ECR repo URL (from Terraform output `ecr_repo`)  

---

## â–¶ï¸ Usage

### 1. Provision Infrastructure
```bash
cd infrastructure
terraform init
terraform apply -auto-approve



---

## ğŸ“ˆ Monitoring & Observability Demo

This environment integrates a **Prometheus + Grafana** monitoring stack using the `kube-prometheus-stack` Helm chart.

It provides real-time metrics, visual dashboards, and alerting for both the Kubernetes cluster and the deployed application.

---

### ğŸ§© Stack Overview

| Component | Purpose |
|------------|----------|
| **Prometheus** | Scrapes metrics from cluster and app targets |
| **Grafana** | Visualizes metrics and dashboards |
| **Alertmanager** | Routes alerts from Prometheus rules |
| **ServiceMonitor** | Custom resource to tell Prometheus which app endpoints to scrape |

---

### ğŸ“Š Grafana â€” Kubernetes Cluster Overview

Shows cluster node health, CPU/memory usage, and pod counts.

![Grafana Cluster Dashboard](screenshots/grafana-cluster.png)

---

### ğŸ§© Grafana â€” Application (web-green) Pod Metrics

Pod-level CPU/memory stats and request throughput for the running web deployment.

![Grafana Web Pod Metrics](screenshots/grafana-web-pods.png)

---

### ğŸ¯ Prometheus â€” Targets Page

Prometheus automatically discovered all service monitors, including the custom `web` ServiceMonitor target.

![Prometheus Targets](screenshots/prometheus-targets.png)

---

### ğŸ“‰ Prometheus â€” Request Count & Probe Success

Demonstrates collected app metrics and blackbox probes.

- **`web_requests_total`** â†’ HTTP requests handled by the app  
- **`probe_success`** â†’ External availability check for ELB endpoint

![Prometheus Metrics Graph](screenshots/prometheus-graph.png)

---

### ğŸš¨ Prometheus â€” Alert Rules & Triggered Alerts

Alerts for high error rate or downtime.  
Here, `WebHighErrorRate` fired when the app returned HTTP 500s.

![Prometheus Alerts](screenshots/prometheus-alerts.png)

---

### ğŸ•µï¸â€â™‚ï¸ Blackbox Exporter â€” Service Availability

Validates that the public endpoint is reachable (HTTP 200 = success).

![Blackbox Probe Result](screenshots/probe-success.png)

---

### ğŸ§¾ Summary

| Area | Tool | Example Metric / Purpose |
|------|------|---------------------------|
| Cluster Health | Grafana | CPU, memory, pod count |
| App Performance | Prometheus | `web_requests_total`, latency |
| Service Availability | Blackbox | `probe_success` |
| Alerting | Prometheus / Alertmanager | High error rate, downtime |

---

### ğŸ§  Key Learnings

- Built **end-to-end observability** into a CI/CD-managed EKS app  
- Exposed custom app metrics with the **prometheus-client** library  
- Automated scraping using **ServiceMonitor** CRDs  
- Integrated **blackbox probing** for uptime visibility  
- Triggered and resolved **custom alert rules**

---
